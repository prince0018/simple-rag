# Simpleâ€¯RAGâ€¯API

Retrievalâ€‘Augmentedâ€‘Generation microâ€‘service built with **LangChainâ€¯+â€¯OpenAI**, served by **FastAPI**, packaged in **Docker**, delivered via **GitHubâ€¯Actions**, and monitored with **Prometheusâ€¯+â€¯Grafana**.

---

## 1Â â€“Â Architecture at a Glance

```
User â”€â–¶ FastAPI (/query) â”€â–¶ LangChain
                       â”‚        â”‚
                       â”‚        â””â”€â–¶ OpenAI LLM
                       â””â”€â–¶ FAISS VectorÂ DB

FastAPI â”€â–¶ /metrics â”€â–¶ Prometheus â”€â–¶ Grafana Dashboard
```

| Layer            | Tool                                    | Purpose                                 |
| ---------------- | --------------------------------------- | --------------------------------------- |
| Vector DB        | **FAISS**                               | Local, lightningâ€‘fast similarity search |
| Embeddings / LLM | **OpenAI** (`adaâ€‘002`, `gptâ€‘3.5â€‘turbo`) | Create embeddings & generate answers    |
| Orchestration    | **LangChain**                           | 3â€‘line `ConversationalRetrievalChain`   |
| WebÂ API          | **FastAPI**                             | Swagger docs, async, `/query` endpoint  |
| Packaging        | **Docker**                              | Reproducible container                  |
| CI/CD            | **GitHubÂ Actions â†’ DockerÂ Hub**         | Autoâ€‘build & push on every `git push`   |
| Metrics          | **prometheus\_fastapi\_instrumentator** | Oneâ€‘liner exposes `/metrics`            |
| Collector        | **Prometheus**                          | Timeâ€‘series DB & PromQL                 |
| Dashboards       | **Grafana**                             | Live graphs + alert rules               |

---

## 2Â â€“Â QuickÂ Start

```bash
# â‘ Â Ingest docs â†’ FAISS
python rag.py --add docs/alex.txt

# â‘¡Â Build + run API
docker build -t simple-rag-api .
docker run -d -p 8000:8000 --env-file .env --name rag-app simple-rag-api
#  http://localhost:8000/docs   (Swagger)
#  http://localhost:8000/metrics (Prometheus)

# â‘¢Â Spinâ€‘up monitoring stack
#   Prometheus
docker run -d -p 9090:9090 \
  -v $PWD/monitoring/prometheus.yml:/etc/prometheus/prometheus.yml \
  --name prometheus prom/prometheus
#   Grafana
docker run -d -p 3000:3000 --name grafana grafana/grafana
#  LoginÂ admin/admin â†’ add Prometheus @ http://host.docker.internal:9090
```

---

## 3Â â€“Â FileÂ Layout

```
simple-rag/
â”œâ”€ app/                 # FastAPI router + LangChain setup
â”œâ”€ faiss_index/         # Vector store on disk
â”œâ”€ docs/                # Source text files
â”œâ”€ monitoring/
â”‚   â””â”€ prometheus.yml   # Prometheus scrape config
â”œâ”€ rag.py               # CLI: ingest + chat
â”œâ”€ main.py              # FastAPI entrypoint
â”œâ”€ Dockerfile
â”œâ”€ requirements.txt
â””â”€ .github/workflows/
    â””â”€ docker-build.yml # CI/CD pipeline
```

---

## 4Â â€“Â CI/CD Pipeline

1. Push to **master** â†’ GitHubÂ Actions fires.
2. Build Docker image.
3. Login to DockerÂ Hub (secrets `DOCKER_USERNAME`, `DOCKER_PASSWORD`).
4. Push `prince0018/simple-rag-api:latest`.

---

## 5Â â€“Â Core Prometheus Queries

| Panel                | Query (PromQL)                                                                          |
| -------------------- | --------------------------------------------------------------------------------------- |
| **QPS**              | `rate(http_requests_total[1m])`                                                         |
| **p95Â Latency**      | `histogram_quantile(0.95, sum by (le)(rate(http_request_duration_seconds_bucket[5m])))` |
| **MemoryÂ Usage**     | `process_resident_memory_bytes`                                                         |
| **ErrorÂ Rate (5xx)** | `rate(http_requests_total{status=~"5.."}[5m])`                                          |

---

## 6Â â€“Â Deploy to EC2 inÂ 3Â Commands

```bash
ssh -i key.pem ec2-user@<IP>
docker pull prince0018/simple-rag-api:latest
echo OPENAI_API_KEY=sk-xxx > .env
docker run -d -p 80:8000 --env-file .env simple-rag-api
```

---

## 7Â â€“Â NextÂ Ideas

- JWT / OAuth auth layer
- Streaming responses over WebSocket
- Autoscale with Kubernetes + HPA
- AlertManager â†’ Slack / eâ€‘mail
- Frontâ€‘end chat (React / Next.js)

> **Result:** A portable, autoâ€‘built, realâ€‘timeâ€‘observable RAG microâ€‘service. Clone, run two Docker commands, start asking questionsÂ ðŸš€

